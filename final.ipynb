{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJfkWa0skV24",
    "outputId": "23870ef4-bb14-4791-a44c-5f4a062e74f4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Provides a way of using operating system dependent functionality. \n",
    "import os\n",
    "\n",
    "# LibROSA provides the audio analysis\n",
    "import librosa\n",
    "# Need to implictly import from librosa\n",
    "import librosa.display\n",
    "\n",
    "# Import the audio playback widget\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Image\n",
    "\n",
    "# Enable plot in the notebook\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# These are generally useful to have around\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# To build Neural Network and Create desired Model\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D #, AveragePooling1D\n",
    "from keras.layers import Flatten, Dropout, Activation # Input, \n",
    "from keras.layers import Dense #, Embedding\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne3rYKt-rCyY"
   },
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXKUj7Gg_xbP"
   },
   "source": [
    "\n",
    "### Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "069SV7_b_xbW",
    "outputId": "99807d0d-c44e-407a-c371-0bd6a9221d8f"
   },
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('Dataset/anger/anger016.wav')\n",
    "# To play audio this in the jupyter notebook\n",
    "ipd.Audio('Dataset/anger/anger016.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "79Lu9GQt_xbg",
    "outputId": "cbfb76c2-7a43-440c-9920-b406376ca99b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbYYBZz4JdQc"
   },
   "source": [
    "### Setup the Basic Paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kntSBjOJsSX"
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.abspath('./Dataset')\n",
    "destination_path = os.path.abspath('./')\n",
    "randomize = True\n",
    "# for spliting dataset into training and testing dataset\n",
    "split = 0.8\n",
    "# Number of sample per second e.g. 16KHz\n",
    "sampling_rate = 20000 \n",
    "emotions=[\"anger\",\"disgust\",\"fear\",\"happy\",\"neutral\", \"sad\", \"surprise\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0lmfGqJrUec"
   },
   "source": [
    "### Converting Dataset in CSV format\n",
    "\n",
    "it will cause easy operation on Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkqxPfRAINO6"
   },
   "outputs": [],
   "source": [
    "#dataset module \n",
    "from utils import dataset\n",
    "df, train_df, test_df = dataset.create_and_load_meta_csv_df(dataset_path, destination_path, randomize, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkSZBQFKXV1U",
    "outputId": "0fbf18e9-c58b-46c7-8044-ad3cf0882530"
   },
   "outputs": [],
   "source": [
    "print('Dataset samples  : ', len(df),\"\\nTraining Samples : \", len(train_df),\"\\ntesting Samples  : \", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukhWNo5dwpJQ"
   },
   "source": [
    "# 4. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXmS7R68wv2w"
   },
   "source": [
    "Let's understand what is our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C-HYIREWSHNY",
    "outputId": "11ad8474-422c-40f4-8095-25214ce1bdb2"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAL9QiMCIPRY",
    "outputId": "2592986a-9f9c-4027-d060-7b419a55c1dc"
   },
   "outputs": [],
   "source": [
    "print(\"Actual Audio : \", df['path'][0])\n",
    "print(\"Labels       : \", df['label'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdScTp-dIOdm"
   },
   "source": [
    "\n",
    "### Labels Assigned for emotions : \n",
    "- 0 : anger\n",
    "- 1 : disgust\n",
    "- 2 : fear\n",
    "- 3 : happy\n",
    "- 4 : neutral \n",
    "- 5 : sad\n",
    "- 6 : surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4eYerYHvNnb",
    "outputId": "b018145b-1402-4fa4-901e-f56d2aa1c7bf"
   },
   "outputs": [],
   "source": [
    "unique_labels = train_df.label.unique()\n",
    "unique_labels.sort()\n",
    "print(\"unique labels in Emtion dataset : \")\n",
    "print(*unique_labels, sep=', ')\n",
    "unique_labels_counts = train_df.label.value_counts(sort=False)\n",
    "print(\"\\n\\nCount of unique labels in Emtion dataset : \")\n",
    "print(*unique_labels_counts,sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "QPk7q3mSvfdz",
    "outputId": "15a623dc-d454-4ca6-bc54-fc99ff5d737a"
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.bar(unique_labels, unique_labels_counts,align = 'center', width=0.6, color = 'c')\n",
    "plt.xlabel('Number of labels', fontsize=16)\n",
    "plt.xticks(unique_labels)\n",
    "plt.ylabel('Count of each labels', fontsize=16)\n",
    "plt.title('Histogram of the Labels', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH92RxJOsCfD"
   },
   "source": [
    "# 5. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwutQfaY_xcK"
   },
   "source": [
    "### Getting the features of audio files using librosa\n",
    "\n",
    "Calculating MFCC, Pitch, magnitude, Chroma features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "_mgOg9iZ_xcL",
    "outputId": "cacf04db-f14c-4df8-c36a-031d995f1c88"
   },
   "outputs": [],
   "source": [
    "from utils.feature_extraction import get_features_dataframe\n",
    "from utils.feature_extraction import get_audio_features\n",
    "\n",
    "trainfeatures, trainlabel = get_features_dataframe(train_df, sampling_rate)\n",
    "testfeatures, testlabel = get_features_dataframe(test_df, sampling_rate)\n",
    "\n",
    "# I have ran above 2 lines and get the featured dataframe. \n",
    "# and store it into pickle file to use it for later purpose.\n",
    "\n",
    "trainfeatures = pd.read_pickle('./features_dataframe/trainfeatures')\n",
    "trainlabel = pd.read_pickle('./features_dataframe/trainlabel')\n",
    "testfeatures = pd.read_pickle('./features_dataframe/testfeatures')\n",
    "testlabel = pd.read_pickle('./features_dataframe/testlabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQtrVqQaVuvh"
   },
   "outputs": [],
   "source": [
    "trainfeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QF4rtHWvXHET"
   },
   "outputs": [],
   "source": [
    "trainfeatures = trainfeatures.fillna(0)\n",
    "testfeatures = testfeatures.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpI4SmIa_xd7"
   },
   "outputs": [],
   "source": [
    "# By using .ravel() : Converting 2D to 1D e.g. (512,1) -> (512,). To prevent DataConversionWarning\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel).ravel()\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlsrszyfmFh1"
   },
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0fYed2umEQo"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQZFrkI5_xd_"
   },
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjBV6h-R_xeK"
   },
   "source": [
    "### Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYYiAIWr_xeN"
   },
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzUvaB10irXl"
   },
   "outputs": [],
   "source": [
    "x_traincnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0uFcWSgsgS4"
   },
   "source": [
    "# 6. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XriCw6__xee"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(x_traincnn.shape[1],x_traincnn.shape[2])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhTkoifP_xej"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZDDACxO_xeq"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb-gPJ5WtrL9"
   },
   "source": [
    "# 7. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S24BSpb4_xew"
   },
   "source": [
    "### Removed the whole training part for avoiding unnecessary long epochs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3b-F2-2_xex"
   },
   "outputs": [],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=400, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-R_5MP9uMDL"
   },
   "source": [
    "### Loss Vs Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyJJGZjg_xe0"
   },
   "outputs": [],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JsmT76h_xe5"
   },
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf2mTXHp_xe6"
   },
   "outputs": [],
   "source": [
    "model_name = 'Speech_Emotion_Recognition_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'Trained_Models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzJYF16p_xe9"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czPDwAVq_xfC"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ug4BC85J_xfD"
   },
   "outputs": [],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Trained_Models/Speech_Emotion_Recognition_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(loaded_model,'ep.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rJ6y8GrxPd4"
   },
   "source": [
    "# 8. Test Set Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrJCxbuq_xfG"
   },
   "source": [
    "### Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWv6Amnt_xfG"
   },
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHMmKejO_xfK"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycDtTVQK_xfN"
   },
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Orw5YaKd_xfP"
   },
   "outputs": [],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cADBzFv0_xfV"
   },
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzXBNNCZ_xfd"
   },
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd-SVnzm_xfl"
   },
   "outputs": [],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1dLnhpW_xfq"
   },
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Pe-1Vzv_xft"
   },
   "outputs": [],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZNx-CUA_xfz"
   },
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akjhl2ux_xf4"
   },
   "source": [
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pp86ztHN_xf5"
   },
   "outputs": [],
   "source": [
    "finaldf[160:175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FidA-G-Z_xf8"
   },
   "outputs": [],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKCZOmr2_xf_"
   },
   "outputs": [],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3--LUd4_xgL"
   },
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
